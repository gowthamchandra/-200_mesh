{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import glob\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import math\n",
    "import plotly.express as px\n",
    "import sys\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats import spearmanr\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.metrics import mean_tweedie_deviance\n",
    "import sys\n",
    "import umap.umap_ as umap\n",
    "def mean_absolute_percentage_error(y_true, y_predicted):\n",
    "    y_true, y_predicted = np.array(y_true), np.array(y_predicted)\n",
    "    return np.mean(np.abs((y_true - y_predicted) / y_true)) * 100\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "os.chdir('/Users/gowtham/Downloads/Final_200/200_mesh_final/Raw_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agg_data=pd.read_csv(\"/Users/gowtham/Downloads/Final_200/200_mesh_final/Raw_Data/Precip_Raw_Data_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m final_cols,columns_to_aggregate,columns_to_resample,resample_frequency,\\\n\u001b[1;32m      2\u001b[0m agg_functions,min_shifts,max_shifts,shifts_per_day,IST_TIMEZONE,Next_Predictions,best_cols,best_model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata_preprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m replace_outliers_with_median,initial_data_preprocessing,\\\n\u001b[1;32m      4\u001b[0m data_aggregation,data_filter,calculate_lag_dates,preparing_lag_data\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils.constants import final_cols,columns_to_aggregate,columns_to_resample,resample_frequency,\\\n",
    "agg_functions,min_shifts,max_shifts,shifts_per_day,IST_TIMEZONE,Next_Predictions,best_cols,best_model\n",
    "from data_preprocessing import replace_outliers_with_median,initial_data_preprocessing,\\\n",
    "data_aggregation,data_filter,calculate_lag_dates,preparing_lag_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "from utils.common import get_current_datetime,sendmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_prediction(final_cols,best_cols,best_model):\n",
    "    df_unseen_PSD = None\n",
    "    if Next_Predictions is True:\n",
    "        final_Agg_data=Agg_data[final_cols]\n",
    "        treated_agg_data = replace_outliers_with_median(final_Agg_data)\n",
    "        df_1hr=initial_data_preprocessing(treated_agg_data)\n",
    "        resampled_df_8hr=data_aggregation(df_1hr)\n",
    "        filtered_df=data_filter(resampled_df_8hr)\n",
    "        final_df=filtered_df.copy()\n",
    "        max_timestamp = final_df['Timestamp_To'].max()\n",
    "        max_timestamp_dt = pd.to_datetime(max_timestamp)\n",
    "        future_timestamp = max_timestamp_dt + timedelta(days=13)\n",
    "        target_date_str = future_timestamp.strftime(\"%Y-%m-%d %H:%M\")\n",
    "        start_date_min_lag, start_date_max_lag = calculate_lag_dates(target_date_str, min_shifts, max_shifts, shifts_per_day)\n",
    "        print(\"Start Date for Minimum Lag:\", start_date_min_lag.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "        print(\"Start Date for Maximum Lag:\", start_date_max_lag.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "        final_df_lag = final_df[(final_df['Timestamp_To'] <= start_date_min_lag) & (final_df['Timestamp_To'] >= start_date_max_lag)]\n",
    "        if len(final_df_lag)<45:\n",
    "            expected_timestamps = pd.date_range(start=start_date_max_lag, end=start_date_min_lag, freq='8H')\n",
    "            missing_timestamps = expected_timestamps.difference(final_df_lag['Timestamp_To'])\n",
    "            missing_rows = pd.DataFrame({col: np.nan for col in final_df_lag.columns}, index=missing_timestamps)\n",
    "            missing_rows['Timestamp_To'] = missing_timestamps\n",
    "            final_df_lag = pd.concat([final_df_lag, missing_rows], ignore_index=True)\n",
    "            final_df_lag.sort_values(by='Timestamp_To', inplace=True)\n",
    "        final_df_lag.sort_values(by='Timestamp_To', inplace=True)\n",
    "        final_df_lag = final_df_lag.interpolate(method='linear',\n",
    "                                               limit_direction='forward')\n",
    "        final_df_lag = final_df_lag.interpolate(method='linear',\n",
    "                                               limit_direction='backward')\n",
    "        final_df_lag.set_index('Timestamp_To', inplace=True)\n",
    "        df_lag_cleaned=preparing_lag_data(final_df_lag)\n",
    "        with open(best_cols, 'rb') as file:\n",
    "            final_cols = pickle.load(file)\n",
    "        df_final_cleaned=df_lag_cleaned[final_cols]\n",
    "        target_column ='Feed_Hydrate_D50'\n",
    "        X_unseen = df_final_cleaned.drop([target_column],axis=1).copy()\n",
    "        y_unseen = df_final_cleaned[[target_column]].copy()\n",
    "        with open(best_model, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        preds = model.predict(X_unseen.values)\n",
    "        print(f\"we are predicting for {future_timestamp}\")\n",
    "        preds=preds.round(2)\n",
    "        df_unseen_PSD=pd.DataFrame()\n",
    "        df_unseen_PSD['Timestamp_To']=X_unseen.index+ timedelta(days=13)\n",
    "        df_unseen_PSD['PSD_Prediction']=preds.round(2)\n",
    "        return df_unseen_PSD\n",
    "    else:\n",
    "        print(\"Latest shift data is not present\")\n",
    "        \n",
    "        return df_unseen_PSD\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
